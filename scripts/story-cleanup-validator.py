#!/usr/bin/env python3
"""
Story Cleanup Validator - Phase 4
Validation et v√©rification des d√©placements
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Tuple

class StoryCleanupValidator:
    def __init__(self, analysis_file: str = "docs/story-analysis-results.json"):
        self.analysis_file = analysis_file
        self.analysis_data = None

    def load_analysis(self) -> bool:
        """Charger les r√©sultats d'analyse"""
        try:
            with open(self.analysis_file, 'r', encoding='utf-8') as f:
                self.analysis_data = json.load(f)
            print(f"‚úÖ Analysis data loaded: {len(self.analysis_data['results'])} files")
            return True
        except Exception as e:
            print(f"‚ùå Error loading analysis: {e}")
            return False

    def verify_file_integrity(self) -> Tuple[int, int, List[str]]:
        """V√©rifier l'int√©grit√© des fichiers d√©plac√©s"""
        success_count = 0
        error_count = 0
        errors = []

        for result in self.analysis_data['results']:
            filename = result['filename']
            destination = result['destination']
            expected_path = f"{destination}/{filename}"

            # V√©rifier que le fichier existe √† sa destination
            if Path(expected_path).exists():
                success_count += 1
            else:
                error_count += 1
                errors.append(f"Missing file: {expected_path}")

        print(f"‚úÖ File integrity: {success_count} OK, {error_count} missing")
        return success_count, error_count, errors

    def verify_symlinks(self) -> Tuple[int, int, List[str]]:
        """V√©rifier que les symlinks fonctionnent"""
        success_count = 0
        error_count = 0
        errors = []

        for result in self.analysis_data['results']:
            filename = result['filename']
            destination = result['destination']

            if destination != "docs/stories/":  # seulement les fichiers d√©plac√©s
                symlink_path = f"docs/stories/{filename}"
                target_path = f"{destination}/{filename}"

                # V√©rifier que le symlink existe
                if not Path(symlink_path).is_symlink():
                    error_count += 1
                    errors.append(f"Missing symlink: {symlink_path}")
                    continue

                # V√©rifier que le symlink pointe vers le bon endroit
                try:
                    resolved_path = os.readlink(symlink_path)
                    expected_relative = os.path.relpath(target_path, f"docs/stories")

                    if resolved_path == expected_relative:
                        success_count += 1
                    else:
                        error_count += 1
                        errors.append(f"Wrong symlink target: {symlink_path} ‚Üí {resolved_path} (expected {expected_relative})")
                except Exception as e:
                    error_count += 1
                    errors.append(f"Error reading symlink {symlink_path}: {e}")

        print(f"‚úÖ Symlinks: {success_count} OK, {error_count} errors")
        return success_count, error_count, errors

    def verify_metadata(self) -> Tuple[int, int, List[str]]:
        """V√©rifier que les m√©tadonn√©es ont √©t√© ajout√©es"""
        success_count = 0
        error_count = 0
        errors = []

        for result in self.analysis_data['results']:
            filename = result['filename']
            destination = result['destination']

            if destination != "docs/stories/":  # seulement les fichiers d√©plac√©s
                file_path = f"{destination}/{filename}"

                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # V√©rifier que les m√©tadonn√©es YAML sont pr√©sentes
                    if content.startswith("---") and "cleanup_status:" in content:
                        success_count += 1
                    else:
                        error_count += 1
                        errors.append(f"Missing metadata in: {file_path}")
                except Exception as e:
                    error_count += 1
                    errors.append(f"Error reading metadata from {file_path}: {e}")

        print(f"‚úÖ Metadata: {success_count} OK, {error_count} missing")
        return success_count, error_count, errors

    def test_symlink_access(self) -> Tuple[int, int, List[str]]:
        """Tester l'acc√®s aux fichiers via symlinks"""
        success_count = 0
        error_count = 0
        errors = []

        for result in self.analysis_data['results']:
            filename = result['filename']
            destination = result['destination']

            if destination != "docs/stories/":  # seulement les fichiers d√©plac√©s
                symlink_path = f"docs/stories/{filename}"

                try:
                    # Essayer de lire le d√©but du fichier via le symlink
                    with open(symlink_path, 'r', encoding='utf-8') as f:
                        content = f.read(100)  # lire les 100 premiers caract√®res

                    if len(content) > 0:
                        success_count += 1
                    else:
                        error_count += 1
                        errors.append(f"Empty content via symlink: {symlink_path}")
                except Exception as e:
                    error_count += 1
                    errors.append(f"Error accessing via symlink {symlink_path}: {e}")

        print(f"‚úÖ Symlink access: {success_count} OK, {error_count} errors")
        return success_count, error_count, errors

    def generate_validation_report(self, integrity_results: Tuple, symlink_results: Tuple,
                                 metadata_results: Tuple, access_results: Tuple) -> str:
        """G√©n√©rer un rapport de validation complet"""
        report = ["# Rapport de Validation - Nettoyage Stories\n"]
        report.append(f"**Date:** {os.popen('date').read().strip()}\n")

        # R√©sum√© g√©n√©ral
        total_files = len(self.analysis_data['results'])
        total_moved = sum(1 for r in self.analysis_data['results'] if r['destination'] != "docs/stories/")

        report.append("## R√©sum√© G√©n√©ral\n")
        report.append(f"- **Total fichiers analys√©s:** {total_files}\n")
        report.append(f"- **Fichiers d√©plac√©s:** {total_moved}\n")
        report.append(f"- **Fichiers rest√©s en place:** {total_files - total_moved}\n")

        # R√©sultats d√©taill√©s
        report.append("## R√©sultats de Validation\n")

        validations = [
            ("Int√©grit√© des fichiers", integrity_results),
            ("Symlinks", symlink_results),
            ("M√©tadonn√©es", metadata_results),
            ("Acc√®s via symlinks", access_results)
        ]

        all_passed = True
        for name, (success, errors, details) in validations:
            status = "‚úÖ PASS" if errors == 0 else "‚ùå FAIL"
            if errors > 0:
                all_passed = False
            report.append(f"### {name}: {status}")
            report.append(f"- Succ√®s: {success}")
            report.append(f"- Erreurs: {errors}")
            if details:
                report.append("- D√©tails des erreurs:")
                for detail in details[:10]:  # limiter √† 10 erreurs max
                    report.append(f"  - {detail}")
                if len(details) > 10:
                    report.append(f"  - ... et {len(details) - 10} autres erreurs")
            report.append("")

        # Conclusion
        report.append("## Conclusion\n")
        if all_passed:
            report.append("üéâ **VALIDATION R√âUSSIE** - Tous les tests sont pass√©s avec succ√®s!\n")
            report.append("Le nettoyage du r√©pertoire stories s'est d√©roul√© parfaitement.\n")
        else:
            report.append("‚ùå **VALIDATION √âCHOU√âE** - Des erreurs ont √©t√© d√©tect√©es.\n")
            report.append("V√©rifiez les d√©tails ci-dessus et consultez les logs pour diagnostiquer les probl√®mes.\n")

        # Statistiques finales
        report.append("## Statistiques par Destination\n")
        dest_stats = {}
        for result in self.analysis_data['results']:
            dest = result['destination']
            if dest != "docs/stories/":
                dest_stats[dest] = dest_stats.get(dest, 0) + 1

        for dest, count in sorted(dest_stats.items()):
            report.append(f"- **{dest}:** {count} fichiers")

        return "\n".join(report)

    def execute_validation(self) -> bool:
        """Ex√©cuter toutes les validations"""
        print("üîç Starting Phase 4: Validation and reporting")

        if not self.load_analysis():
            return False

        # Ex√©cuter toutes les validations
        integrity = self.verify_file_integrity()
        symlinks = self.verify_symlinks()
        metadata = self.verify_metadata()
        access = self.test_symlink_access()

        # G√©n√©rer le rapport
        report = self.generate_validation_report(integrity, symlinks, metadata, access)

        with open("docs/story-cleanup-validation-report.md", 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"üìä Validation report generated: docs/story-cleanup-validation-report.md")

        # V√©rifier si tout est OK
        all_good = all(errors == 0 for _, errors, _ in [integrity, symlinks, metadata, access])

        if all_good:
            print("‚úÖ Phase 4 completed: ALL VALIDATIONS PASSED")
        else:
            print("‚ùå Phase 4 completed: SOME VALIDATIONS FAILED")

        return all_good

def main():
    validator = StoryCleanupValidator()
    success = validator.execute_validation()

    if success:
        print("üéâ Story cleanup validation: SUCCESS")
    else:
        print("‚ùå Story cleanup validation: ISSUES DETECTED")

if __name__ == "__main__":
    main()
